"""
å‘Šè­¦è¦å‰‡ Redis å¿«å–æœå‹™

ç®¡ç†å‘Šè­¦è¦å‰‡çš„ Redis å¿«å–ï¼Œæä¾›é«˜æ•ˆçš„è¦å‰‡æŸ¥è©¢å’Œå¿«å–ç®¡ç†åŠŸèƒ½ã€‚
åœ¨ç³»çµ±å•Ÿå‹•æ™‚è¼‰å…¥è¦å‰‡ï¼Œåœ¨è¦å‰‡è®Šæ›´æ™‚æ›´æ–°å¿«å–ã€‚
"""

import asyncio
import json
import logging
import os
from datetime import datetime
from typing import Any, Dict, List, Optional

import redis
from shared.database.alert_queries import get_active_alert_rules

# è¨­å®š logger
logger = logging.getLogger(__name__)


class AlertCacheService:
    """å‘Šè­¦è¦å‰‡ Redis å¿«å–æœå‹™"""

    def __init__(self, redis_client: redis.Redis):
        """
        åˆå§‹åŒ–å‘Šè­¦å¿«å–æœå‹™

        Args:
            redis_client (redis.Redis): Redis å®¢æˆ¶ç«¯å¯¦ä¾‹
        """
        self.redis = redis_client
        self.cache_key = "alert_rules:active"
        self.cache_ttl = 3600  # 1å°æ™‚éæœŸ
        self.last_updated_key = "alert_rules:last_updated"

    async def load_rules_to_cache(self) -> bool:
        """
        å¾è³‡æ–™åº«è¼‰å…¥å‘Šè­¦è¦å‰‡åˆ° Redis å¿«å–

        Returns:
            bool: è¼‰å…¥æ˜¯å¦æˆåŠŸ
        """
        try:
            logger.info("ğŸ”„ é–‹å§‹è¼‰å…¥å‘Šè­¦è¦å‰‡åˆ° Redis å¿«å–...")

            # å¾è³‡æ–™åº«ç²å–å•Ÿç”¨çš„è¦å‰‡
            rules = get_active_alert_rules()

            if not rules:
                logger.warning("âš ï¸ æ²’æœ‰æ‰¾åˆ°å•Ÿç”¨çš„å‘Šè­¦è¦å‰‡")
                return False

            # æº–å‚™å¿«å–è³‡æ–™
            cache_data = {
                "rules": rules,
                "last_updated": datetime.now().isoformat(),
                "count": len(rules),
            }

            # å­˜å„²åˆ° Redis
            self.redis.setex(
                self.cache_key,
                self.cache_ttl,
                json.dumps(cache_data, ensure_ascii=False),
            )

            # æ›´æ–°æœ€å¾Œæ›´æ–°æ™‚é–“
            self.redis.setex(
                self.last_updated_key, self.cache_ttl, datetime.now().isoformat()
            )

            logger.info(f"âœ… æˆåŠŸè¼‰å…¥ {len(rules)} å€‹å‘Šè­¦è¦å‰‡åˆ° Redis å¿«å–")
            return True

        except Exception as e:
            logger.error(f"âŒ è¼‰å…¥å‘Šè­¦è¦å‰‡åˆ°å¿«å–å¤±æ•—: {e}")
            return False

    async def get_cached_rules(self) -> Optional[List[Dict[str, Any]]]:
        """
        å¾ Redis ç²å–å¿«å–çš„å‘Šè­¦è¦å‰‡

        Returns:
            Optional[List[Dict[str, Any]]]: å¿«å–çš„è¦å‰‡åˆ—è¡¨ï¼Œå¦‚æœæ²’æœ‰å‰‡è¿”å› None
        """
        try:
            cached_data = self.redis.get(self.cache_key)

            if cached_data:
                data = json.loads(cached_data)
                rules = data.get("rules", [])
                logger.info(f"âœ… å¾ Redis å¿«å–ç²å– {len(rules)} å€‹å‘Šè­¦è¦å‰‡")
                return rules
            else:
                logger.warning("âš ï¸ Redis å¿«å–ä¸­æ²’æœ‰å‘Šè­¦è¦å‰‡")
                return None

        except Exception as e:
            logger.error(f"âŒ å¾ Redis ç²å–å‘Šè­¦è¦å‰‡å¤±æ•—: {e}")
            return None

    async def get_active_rules(self) -> List[Dict[str, Any]]:
        """
        ç²å–å•Ÿç”¨çš„å‘Šè­¦è¦å‰‡ï¼ˆå„ªå…ˆå¾å¿«å–ï¼Œå¿«å–ç‚ºç©ºæ™‚å¾è³‡æ–™åº«è¼‰å…¥ï¼‰

        Returns:
            List[Dict[str, Any]]: å‘Šè­¦è¦å‰‡åˆ—è¡¨
        """
        # å…ˆå˜—è©¦å¾å¿«å–ç²å–
        rules = await self.get_cached_rules()

        if rules is not None:
            return rules

        # å¿«å–ç‚ºç©ºï¼Œå¾è³‡æ–™åº«è¼‰å…¥
        logger.info("ğŸ”„ å¿«å–ç‚ºç©ºï¼Œå¾è³‡æ–™åº«è¼‰å…¥å‘Šè­¦è¦å‰‡...")
        success = await self.load_rules_to_cache()

        if success:
            return await self.get_cached_rules() or []
        else:
            # è¼‰å…¥å¤±æ•—ï¼Œç›´æ¥å¾è³‡æ–™åº«ç²å–
            logger.warning("âš ï¸ å¿«å–è¼‰å…¥å¤±æ•—ï¼Œç›´æ¥å¾è³‡æ–™åº«ç²å–è¦å‰‡...")
            return get_active_alert_rules()


# æ¸¬è©¦å‡½æ•¸
async def test_alert_cache_service():
    """æ¸¬è©¦å‘Šè­¦å¿«å–æœå‹™"""
    logger.info("ğŸ§ª æ¸¬è©¦å‘Šè­¦å¿«å–æœå‹™")
    logger.info("=" * 50)

    # å‰µå»º Redis å®¢æˆ¶ç«¯ï¼ˆéœ€è¦ç¢ºä¿ Redis æœå‹™é‹è¡Œï¼‰
    try:
        redis_url = os.getenv("REDIS_URL", "redis://localhost:6379")
        redis_client = redis.from_url(redis_url, decode_responses=True)
        # æ¸¬è©¦é€£æ¥
        redis_client.ping()
        logger.info("âœ… Redis é€£æ¥æˆåŠŸ")
    except Exception as e:
        logger.error(f"âŒ Redis é€£æ¥å¤±æ•—: {e}")
        return

    # å‰µå»ºå¿«å–æœå‹™
    cache_service = AlertCacheService(redis_client)

    # æ¸¬è©¦è¼‰å…¥è¦å‰‡åˆ°å¿«å–
    logger.info("\n1. æ¸¬è©¦è¼‰å…¥è¦å‰‡åˆ°å¿«å–:")
    success = await cache_service.load_rules_to_cache()
    logger.info(f"   è¼‰å…¥çµæœ: {'æˆåŠŸ' if success else 'å¤±æ•—'}")

    # æ¸¬è©¦ç²å–å¿«å–è¦å‰‡
    logger.info("\n2. æ¸¬è©¦ç²å–å¿«å–è¦å‰‡:")
    rules = await cache_service.get_cached_rules()
    if rules:
        logger.info(f"   ç²å–åˆ° {len(rules)} å€‹è¦å‰‡")
        for rule in rules[:3]:  # åªé¡¯ç¤ºå‰3å€‹
            logger.info(
                f"   - {rule.get('rule_name')}: {rule.get('rule_type')} {rule.get('change_direction')}"
            )
    else:
        logger.info("   æ²’æœ‰ç²å–åˆ°è¦å‰‡")

    # æ¸¬è©¦ç²å–æ‰€æœ‰è¦å‰‡
    logger.info("\n3. æ¸¬è©¦ç²å–æ‰€æœ‰è¦å‰‡:")
    all_rules = await cache_service.get_active_rules()
    logger.info(f"   ç¸½è¦å‰‡æ•¸: {len(all_rules)}")
    for rule in all_rules[:3]:  # åªé¡¯ç¤ºå‰3å€‹
        logger.info(
            f"   - {rule.get('rule_name')}: {rule.get('rule_type')} {rule.get('change_direction')}"
        )

    logger.info("\nâœ… å‘Šè­¦å¿«å–æœå‹™æ¸¬è©¦å®Œæˆ")


if __name__ == "__main__":
    asyncio.run(test_alert_cache_service())
