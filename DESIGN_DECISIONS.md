# 技術決策說明

## 1. 架構決策概述

本文檔記錄了 Amazon 產品監控與優化工具在設計和開發過程中的關鍵技術決策，包括決策背景、選型理由、替代方案分析以及預期影響。

## 2. 核心架構決策

### 2.1 微服務架構 vs 單體架構

**決策：** 採用微服務架構

**背景：** 系統需要支援多個獨立的功能模組（產品追蹤、告警、分析），並且需要具備良好的擴展性和維護性。

**選型理由：**
- **獨立部署：** 各服務可以獨立開發、測試和部署
- **技術多樣性：** 不同服務可以使用最適合的技術棧
- **故障隔離：** 單一服務故障不會影響整個系統
- **團隊協作：** 不同團隊可以獨立負責不同服務

**替代方案：** 單體架構
- **優點：** 開發簡單、部署簡單、調試容易
- **缺點：** 擴展困難、技術棧受限、團隊協作困難

**預期影響：**
- **正面：** 提高系統可維護性和擴展性
- **負面：** 增加系統複雜度，需要額外的服務治理

### 2.2 報告資料庫設計：任務狀態管理

**決策：** 使用專門的資料表管理報告任務狀態和結果

**背景：** 競品分析報告生成需要完整的任務生命週期管理和結果存儲。

**選型理由：**
- **狀態追蹤：** 完整的任務狀態管理（pending → running → completed/failed）
- **結果存儲：** 支援大型報告內容的存儲
- **冪等性控制：** 基於參數雜湊值的重複檢查
- **查詢效能：** 針對報告查詢模式優化索引
- **資料完整性：** 外鍵約束確保資料一致性

**資料表設計：**

**報告任務表 (report_jobs)：**
- 使用 UUID 作為主鍵，確保全域唯一性
- 包含任務類型、參數、參數雜湊值等基本資訊
- 記錄任務狀態（pending、running、completed、failed）
- 追蹤任務的創建、開始、完成時間
- 支援錯誤訊息記錄和結果 URL 存儲

**報告結果表 (report_results)：**
- 與報告任務表建立外鍵關聯
- 存儲報告內容（Markdown 格式）
- 包含報告元資料（JSON 格式）
- 支援大型報告內容的存儲

**設計特點：**
- **分離設計：** 任務狀態和結果內容分開存儲
- **JSON 支援：** 使用 JSONB 存儲靈活的參數和元資料
- **雜湊索引：** 基於參數雜湊值快速查詢重複任務
- **時間追蹤：** 記錄任務的創建、開始、完成時間
- **錯誤處理：** 專門的錯誤訊息欄位

**替代方案：**
1. **單一資料表：** 簡單但會導致資料表過大
2. **檔案存儲：** 報告存儲在檔案系統，但缺乏查詢能力
3. **NoSQL 資料庫：** 使用 MongoDB 等，但增加系統複雜度

**預期影響：**
- **正面：** 提供完整的報告任務管理能力，支援冪等性控制
- **負面：** 增加資料庫複雜度，需要額外的查詢優化

### 2.3 任務佇列：Celery + Redis

**決策：** 使用 Celery 作為分散式任務佇列，Redis 作為訊息代理

**背景：** 系統需要處理大量的異步任務（資料擷取、告警檢查、通知發送）。

**選型理由：**
- **成熟穩定：** Celery 是 Python 生態系統中最成熟的任務佇列
- **豐富功能：** 支援任務重試、優先級、排程等功能
- **監控友好：** 提供豐富的監控和管理工具
- **擴展性：** 支援水平擴展和負載均衡
- **整合性：** 與 Django/FastAPI 等框架整合良好

**實際實現：**
- 使用 Redis 作為 Celery 的訊息代理和結果後端
- 實現了 `amazon_queue` 和 `report_queue` 兩個佇列
- 配置了 Celery Beat 進行定時任務排程
- 使用 Flower 進行任務監控和管理

**替代方案：**
1. **RQ (Redis Queue)：** 簡單但功能有限
2. **Apache Kafka：** 功能強大但過於複雜
3. **AWS SQS：** 雲端服務但增加依賴

**預期影響：**
- **正面：** 提供可靠的異步任務處理能力
- **負面：** 需要額外的 Redis 資源和監控


### 2.4 API 框架：FastAPI

**決策：** 使用 FastAPI 作為 API 服務框架

**背景：** 系統需要提供 RESTful API 接口，需要高效能和易於維護的框架。

**選型理由：**
- **高效能：** 基於 Starlette 和 Pydantic，效能優異
- **自動文檔：** 自動生成 OpenAPI 文檔和 Swagger UI
- **類型提示：** 完整的 Python 類型提示支援
- **異步支援：** 原生支援 async/await
- **易於測試：** 內建測試客戶端

**實際實現：**
- 實現了模組化的路由結構（`routers/` 目錄）
- 提供了健康檢查、Hello World、Webhook 等端點
- 使用 Pydantic 進行資料驗證
- 整合了 CORS 中間件支援跨域請求

**替代方案：**
1. **Django REST Framework：** 功能完整但較重
2. **Flask：** 輕量但需要更多配置
3. **Express.js：** JavaScript 生態但需要切換語言

**預期影響：**
- **正面：** 快速開發，自動文檔生成，高效能
- **負面：** 相對較新的框架，生態系統較小


### 2.3 排程管理：Celery Beat vs Apify Schedules

**決策：** 使用 Celery Beat 進行排程管理

**背景：** 需要定期執行資料抓取任務，需要靈活的排程控制和更好的系統整合。

**選型理由：**
- **統一架構：** 與 Celery Worker 使用相同的技術棧
- **靈活控制：** 可以動態調整要追蹤的 ASIN 列表
- **錯誤處理：** 更好的錯誤處理和重試機制
- **監控能力：** 可以整合到現有的監控系統（Flower）
- **成本控制：** 避免 Apify Schedules 的額外費用
- **任務管理：** 統一的任務狀態管理和追蹤

**實現方式：**

**排程配置：**
- 在 `celery_config.py` 中定義 Celery Beat 排程
- Amazon 產品抓取：每2分鐘執行一次，從資料庫獲取待處理的 ASIN 列表
- 報告清理：每天凌晨2點執行，清理過期的報告資料
- 報告健康監控：每10分鐘執行一次，檢查報告生成狀態

**任務流程：**
- 排程器定期觸發任務，從資料庫獲取需要抓取的 ASIN 列表
- 將 ASIN 列表分發給 Celery Worker 進行並行處理
- 使用 `get_pending_asins()` 函數獲取待處理的 ASIN
- 通過 `fetch_amazon_products.delay()` 將任務發送到 Worker 佇列

**替代方案：**
1. **Apify Schedules：** 簡單但缺乏靈活性
2. **微服務 Cron：** 需要額外的排程服務
3. **Kubernetes CronJob：** 適合容器化環境

**預期影響：**
- **正面：** 提供統一的任務管理和排程控制
- **負面：** 需要額外的 Celery Beat 服務維護

### 2.4 任務處理：Celery 微服務架構

**決策：** 使用 Celery 微服務處理 ASIN 批次任務

**背景：** 需要處理大量 ASIN 的並行抓取，需要水平擴展和故障隔離。

**選型理由：**
- **水平擴展：** 可以根據負載動態調整 Worker 數量
- **故障隔離：** 單一 Worker 故障不影響其他 Worker
- **任務管理：** 內建重試、優先級、狀態追蹤
- **監控友好：** 提供豐富的監控和管理工具
- **成熟穩定：** 經過大量生產環境驗證

**架構設計：**

**任務定義：**
- 使用 Celery 裝飾器定義異步任務
- 設定最大重試次數為3次，確保任務可靠性
- 支援 ASIN 批次處理，提高處理效率
- 包含 ASIN 數量限制檢查，防止過載

**處理流程：**
- 接收 ASIN 列表和任務 ID 作為參數
- 檢查 ASIN 數量是否超過批次限制
- 使用 AmazonDataCollector 進行資料抓取
- 返回處理結果和任務狀態

**任務流程：**
1. **Cron 服務**：定時觸發，從資料庫獲取 ASIN 列表
2. **任務分發**：將 ASIN 分批發送到 Celery 佇列
3. **Celery Worker**：並行處理 ASIN 批次
4. **結果存儲**：將結果存儲到資料庫和 Apify Dataset

**替代方案：**
1. **直接處理**：Cron 服務直接處理所有 ASIN
2. **多進程**：使用 multiprocessing 處理
3. **Kubernetes Jobs**：使用 K8s 任務調度

**預期影響：**
- **正面：** 提供水平擴展能力和故障隔離
- **負面：** 增加系統複雜度和維護成本

### 2.5 競品分析報告：非同步生成架構

**決策：** 使用非同步任務 + OpenAI LLM 生成競品分析報告

**背景：** 競品分析報告生成需要大量資料處理和比較分析，需要非同步處理以避免阻塞 API 響應。使用 LLM 可以生成更專業、更人性化的報告內容。

**選型理由：**
- **響應性：** 立即返回 202 Accepted，避免長時間阻塞
- **可擴展性：** 可以並行處理多個報告生成任務
- **可靠性：** 任務失敗時可以重試，不會丟失請求
- **監控性：** 可以追蹤任務狀態和進度
- **冪等性：** 支援相同參數的重複請求檢查
- **AI 增強：** 使用 LLM 生成專業、結構化的報告內容
- **靈活性：** 可以根據不同需求調整報告格式和內容

**架構設計：**

**API 端點設計：**
- 接收競品分析報告請求，使用 Pydantic 進行參數驗證
- 檢查冪等性，避免重複生成相同報告
- 創建報告任務記錄，生成唯一的任務 ID
- 將任務發送到 Celery 佇列進行異步處理
- 立即返回 202 Accepted 狀態和任務查詢 URL

**Celery 任務處理：**
- 更新任務狀態為 running，開始處理
- 使用 CompetitorAnalyzer 收集產品和競品資料
- 調用 LLMReportGenerator 生成專業報告內容
- 保存報告結果到資料庫
- 更新任務狀態為 completed 或 failed
- 包含完整的錯誤處理和重試機制

**任務流程：**
1. **API 接收請求**：驗證參數，檢查冪等性
2. **創建任務記錄**：在資料庫中創建報告任務記錄
3. **返回 202 Accepted**：立即返回任務 ID 和狀態查詢 URL
4. **Celery 處理**：背景生成報告內容
5. **資料收集**：獲取主產品和競品的詳細資料
6. **LLM 生成**：使用 OpenAI API 生成專業報告
7. **狀態更新**：實時更新任務狀態
8. **結果存儲**：保存報告結果到資料庫
9. **客戶端輪詢**：客戶端定期查詢任務狀態

**冪等性設計：**
- **參數雜湊**：基於請求參數生成唯一雜湊值
- **時間窗口**：同一天內相同參數直接返回已生成報告
- **狀態檢查**：避免重複生成相同報告

**替代方案：**
1. **同步處理**：簡單但會阻塞 API 響應
2. **WebSocket**：即時通知但增加複雜度
3. **事件驅動**：使用事件總線但需要額外基礎設施

**預期影響：**
- **正面：** 提高 API 響應性，支援大規模報告生成
- **負面：** 增加系統複雜度，需要客戶端輪詢機制

### 2.6 資料處理：批次處理 + 即時處理

**決策：** 採用批次處理為主，即時處理為輔的混合模式

**背景：** 系統需要處理大量產品資料，需要平衡處理效率和即時性。

**處理策略：**
- **批次處理：** 每日定時擷取所有產品資料
- **即時處理：** 緊急情況下手動觸發資料更新
- **增量處理：** 只處理變化的資料，提高效率

**替代方案：**
1. **純即時處理：** 響應快但資源消耗大
2. **純批次處理：** 資源效率高但響應慢

**預期影響：**
- **正面：** 平衡了處理效率和資源使用
- **負面：** 增加了系統複雜度

## 3. 監控與維運決策

### 3.1 基本監控：Flower + 終端日誌

**決策：** 使用 Flower 進行 Celery 任務監控，終端輸出進行日誌記錄

**背景：** 系統需要基本的監控能力來確保任務正常執行。

**選型理由：**
- **簡單有效：** Flower 提供直觀的 Celery 任務監控界面
- **即時監控：** 可以即時查看任務執行狀態和 Worker 狀態
- **易於部署：** 無需複雜配置，快速啟動
- **成本低廉：** 開源免費，無額外成本

**實際實現：**
- 使用 Flower 監控 Celery Worker 和任務狀態
- 通過終端輸出記錄詳細的執行日誌
- 實現了基本的錯誤處理和重試機制
- 提供了簡單的測試腳本驗證系統功能

**替代方案：**
1. **Prometheus + Grafana：** 功能完整但配置複雜
2. **ELK Stack：** 日誌分析強大但資源消耗大
3. **商業監控：** 功能完整但成本較高

**預期影響：**
- **正面：** 簡單易用，快速部署，滿足基本監控需求
- **負面：** 功能相對簡單，缺乏進階分析能力
